"""
CLI Chatbot with RAG (Hospital + Hotel)
- Context-aware assistant with role selection.
- Retrieval-Augmented Generation (RAG) using JSON datasets.
- Commands: /reset /exit /help
"""

import os
import sys
import argparse
from typing import List, Dict

from dotenv import load_dotenv

# ---- LangChain / RAG imports ----
import json
from langchain.schema import Document
from langchain.text_splitter import CharacterTextSplitter
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain_chroma import Chroma
from langchain.memory import ConversationBufferMemory
from langchain.chains import ConversationalRetrievalChain

# ---------------- Config ----------------
load_dotenv(override=True)
MODEL = os.getenv("OPENAI_MODEL", "gpt-4o-mini")
TEMPERATURE = float(os.getenv("CHAT_TEMPERATURE", "0.4"))
MAX_TURNS_MEMORY = 8
DB_NAME = "vector_db"

# ---------------- Role Prompts ----------------
HOSPITAL_SYSTEM_PROMPT = """You are Miroka√Ø, a courteous hospital assistant robot.
Goals:
- Greet warmly, keep responses concise and reassuring.
- Clarify requests (who/what/where/when) before acting.
- NEVER give medical advice; defer to medical staff for diagnoses/treatments.
- You can provide directions, general info, hospital facility info, and polite small talk.
Tone: calm, supportive, professional, accessible to non-experts."""

CONCIERGE_SYSTEM_PROMPT = """You are Miroka√Ø, a friendly concierge robot in a hotel lobby.
Goals:
- Greet guests, answer questions, give directions and recommendations.
- Ask short clarifying questions before giving long answers.
- Be specific when possible (times, locations, steps).
Tone: upbeat, helpful, slightly playful but always professional."""

ROLE_TO_PROMPT = {
    "hospital": HOSPITAL_SYSTEM_PROMPT,
    "hotel": CONCIERGE_SYSTEM_PROMPT,
}

ROLE_TO_DATASET = {
    "hospital": "california_general_hospital.json",
    "hotel": "Concierge_dataset.json",
}

# -------------- Build RAG Pipeline --------------
def build_rag_chain(json_file: str):
    # Load JSON
    with open(json_file, "r", encoding="utf-8") as f:
        data = json.load(f)

    documents = []

    # Flatten JSON into documents
    def flatten_dict(d, prefix=""):
        text_parts = []
        if isinstance(d, dict):
            for k, v in d.items():
                text_parts.extend(flatten_dict(v, f"{prefix}{k} "))
        elif isinstance(d, list):
            for item in d:
                text_parts.extend(flatten_dict(item, prefix))
        else:
            text_parts.append(f"{prefix}{d}")
        return text_parts

    flat_text = " ".join(flatten_dict(data))
    documents.append(Document(page_content=flat_text, metadata={"source": json_file}))

    # Split into chunks
    splitter = CharacterTextSplitter(chunk_size=500, chunk_overlap=50)
    chunks = splitter.split_documents(documents)

    embeddings = OpenAIEmbeddings()

    # Fresh vector DB
    if os.path.exists(DB_NAME):
        Chroma(persist_directory=DB_NAME, embedding_function=embeddings).delete_collection()

    vectorstore = Chroma.from_documents(chunks, embedding=embeddings, persist_directory=DB_NAME)

    llm = ChatOpenAI(model_name=MODEL, temperature=TEMPERATURE)

    memory = ConversationBufferMemory(memory_key="chat_history", k=MAX_TURNS_MEMORY, return_messages=True)

    chain = ConversationalRetrievalChain.from_llm(llm=llm, retriever=vectorstore.as_retriever(), memory=memory)

    return chain

# -------------- Chatbot Wrapper --------------
class Chatbot:
    def __init__(self, role: str, rag_chain, verbose: bool = False):
        self.role = role
        self.system_prompt = ROLE_TO_PROMPT[role]
        self.verbose = verbose
        self.chain = rag_chain

    def ask(self, user_text: str) -> str:
        query = f"{self.system_prompt}\nUser: {user_text}"
        result = self.chain.invoke({"question": query})
        return result["answer"]

    def reset(self):
        # Reset conversation memory
        self.chain.memory.clear()

# -------------- CLI Loop --------------
def print_header(role: str):
    print("=" * 64)
    print(f"Miroka√Ø CLI Chatbot  ‚Ä¢  Role: {role.capitalize()}")
    print("Commands: /reset  /exit  /help")
    print("=" * 64)

def main():
    parser = argparse.ArgumentParser()
    parser.add_argument("--role", choices=["hospital", "hotel"], default=None,
                        help="Choose chatbot role")
    parser.add_argument("--verbose", action="store_true")
    args = parser.parse_args()

    # If no role provided, ask interactively
    role = args.role
    if not role:
        role = input("Choose role (hospital/hotel): ").strip().lower()
        if role not in ROLE_TO_PROMPT:
            print("Invalid role. Exiting.")
            return

    dataset = ROLE_TO_DATASET[role]
    rag_chain = build_rag_chain(dataset)
    bot = Chatbot(role=role, rag_chain=rag_chain, verbose=args.verbose)

    print_header(role)

    greeting = {
        "hospital": "Hello, I'm Miroka√Ø. How can I help you today? (I can give directions and hospital info; I don't provide medical advice.)",
        "hotel": "Welcome! I'm Miroka√Ø at your service. What can I help you with‚Äîdirections, recommendations, or check-in info?"
    }[role]
    print(f"Miroka√Ø: {greeting}")

    while True:
        try:
            user_text = input("You: ").strip()
        except (KeyboardInterrupt, EOFError):
            print("\nMiroka√Ø: Goodbye! üëã")
            break

        if not user_text:
            continue
        if user_text.lower() in ("/exit", "/quit"):
            print("Miroka√Ø: Goodbye! üëã")
            break
        if user_text.lower() == "/help":
            print("Miroka√Ø: Commands ‚Üí /reset (clear context), /exit (quit), /help (this help)")
            continue
        if user_text.lower() == "/reset":
            bot.reset()
            print("Miroka√Ø: Context cleared. How can I help now?")
            continue

        reply = bot.ask(user_text)
        print(f"Miroka√Ø: {reply}")

if __name__ == "__main__":
    main()
